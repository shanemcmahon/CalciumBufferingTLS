plot(rnorm(20),rnorm(20),panel = 1)
plot(rnorm(20),rnorm(20),panel = 2)
?plot.new
?plot.window
?dev.control
?dev.cur
dev.list()
?layout
?lcm
layout.show(1)
plot(rnorm(20),rnorm(20))
layout.show(1)
layout.show(2)
plot(rnorm(20),rnorm(20))
layout.show(2)
dev.cur()
plot(rnorm(20),rnorm(20))
plot(rnorm(20),rnorm(20))
split.screen(figs = c(2,2))
plot(rnorm(20),rnorm(20))
plot(rnorm(20),rnorm(20))
plot(rnorm(20),rnorm(20))
screen(n=1)
split.screen(figs = c(2,2))
plot(rnorm(20),rnorm(20))
screen(n=1)
plot(rnorm(20),rnorm(20))
plot(rnorm(20),rnorm(20))
plot(rnorm(20),rnorm(20))
plot(rnorm(20),rnorm(20))
plot(rnorm(20),rnorm(20))
screen(n=2)
plot(rnorm(20),rnorm(20))
dev.new()
split.screen(figs = c(2,2))
plot.new()
dev.new()
plot.new()
dev.new()
plot.new()
split.screen(figs = c(2,2))
screen(n=1)
plot(rnorm(20),rnorm(20))
plot(rnorm(20),rnorm(20))
screen(n=2)
plot(rnorm(20),rnorm(20))
screen(n=1)
plot(rnorm(20),rnorm(20))
screen(n=2)
plot(rnorm(20),rnorm(20),col=2)
screen(n=3)
plot(rnorm(20),rnorm(20),col=3)
screen(n=4)
plot(rnorm(20),rnorm(20),col=4)
screen(n=1)
plot(rnorm(20),rnorm(20),col=5)
dev.cur()
require("data.table")
file.choose()
file.choose()
source('~/CalciumBufferingTLS/Setup.Ca.Buffering.TLS.R')
getwd()
?file.choose
choose.files()
choose.files()
dat.file.name <- choose.files()
dat.file.name
dat.file.name <- choose.files(default = F:\\calcium_imaging\\curated_calcium_images\\fluo-8)
dat.file.name <- choose.files(default = "F:\\calcium_imaging\\curated_calcium_images\\fluo-8")
dat.file.name
dat.file.name <- choose.files(default = "F:\\calcium_imaging\\curated_calcium_images\\fluo-8")
dat.file.name
dat.1 <- read.csv()
dat.1 <- read.csv(dat.file.name)
dat.1
source('F:/r_code/CalciumBufferingNEsTLeS/Utility.Functions.R')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
x <- (1:100)/100
beta <- runif(3)
beta[1]
y <- beta[1] + beta[2] * exp(beta[3]*x)
plot(x,y)
beta
beta <- runif(3)
y <- beta[1] + beta[2] * exp(beta[3]*x)
plot(x,y)
beta <- runif(3)
y <- beta[1] + beta[2] * exp(beta[3]*x)
plot(x,y)
beta <- runif(3)
y <- beta[1] + beta[2] * exp(beta[3]*x)
plot(x,y)
beta <- runif(3)
y <- beta[1] + beta[2] * exp(beta[3]*x)
plot(x,y)
rnorm(length(x),sd = .05)
plot(x,y)
y <- y + rnorm(length(x),sd = .05)
plot(x,y)
lm(y~exp(x))
attributes(beta)$names <- c("a","b","c")
beta
nls( y ~ a * b + exp(c*x), start = beta)
beta <- runif(3)
attributes(beta)$names <- c("a","b","c")
y <- beta[1] + beta[2] * exp(beta[3]*x)
y <- y + rnorm(length(x),sd = .05)
nls( y ~ a * b + exp(c*x), start = beta)
y
lm(y~exp(x))
beta
beta <- 1 + runif(3)
attributes(beta)$names <- c("a","b","c")
y <- beta[1] + beta[2] * exp(beta[3]*x)
y <- y + rnorm(length(x),sd = .05)
lm(y~exp(x))
nls( y ~ a * b + exp(c*x), start = beta)
nls( y ~ a * b + exp(c*x), start = beta*.5)
beta
beta <- 1 + runif(3)*5
attributes(beta)$names <- c("a","b","c")
y <- beta[1] + beta[2] * exp(beta[3]*x)
y <- y + rnorm(length(x),sd = .05)
lm(y~exp(x))
nls( y ~ a * b + exp(c*x), start = beta)
y
plot(x,y)
y <- y + rnorm(length(x),sd = 1)
plot(x,y)
lm(y~exp(x))
nls( y ~ a * b + exp(c*x), start = beta)
nls( y ~ a * b + exp(c*x), start = beta, data(data.frame(x=x,y=y)))
data.frame(x=x,y=y)
nls( y ~ a * b + exp(c*x), start = beta, data=(data.frame(x=x,y=y)))
?nls
??nlm
??nls
?nlxb
??nlxb
beta
nls( y ~ a * b + exp(c*x), start = c(a=1,b=1,c=1), data=(data.frame(x=x,y=y)))
a * b + exp(c*x)
beta[1] + beta[2] * exp(beta[3]*x)
require(minpack.lm)
nlsLM( y ~ a * b + exp(c*x), start = c(a=1,b=1,c=1), data=(data.frame(x=x,y=y)))
x <- (1:100)/100
beta <- 1 + runif(3)*5
attributes(beta)$names <- c("a","b","c")
y <- beta[1] + beta[2] * exp(beta[3]*x)
y <- y + rnorm(length(x),sd = 2)
plot(x,y)
lm(y~exp(x))
nls( y ~ a * b + exp(c*x), start = c(a=1,b=1,c=1), data=(data.frame(x=x,y=y)))
x <- (1:100)/100
beta <- 1 + runif(3)*5
attributes(beta)$names <- c("a","b","c")
y <- beta[1] + beta[2] * exp(beta[3]*x)
y <- y + rnorm(length(x),sd = 2)
plot(x,y)
lm(y~exp(x))
nls( y ~ a * b + exp(c*x), start = c(a=1,b=1,c=1), data=(data.frame(x=x,y=y)))
nls(formula = y ~ a * b + exp(c*x),data = (data.frame(x=x,y=y)),start = c(a=1,b=1,c=1) )
nls.lm(par = beta, fn = function(par){y - (par[1] + par[2] * exp(par[3]*x))})
beta
setwd("F:/2013/kd estimation/CalciumBufferingTLS")
source('F:/2013/kd estimation/CalciumBufferingTLS/Run.Ca.Buffering.TLS.R')
source('F:/2013/kd estimation/CalciumBufferingTLS/Run.Ca.Buffering.TLS.R')
max.iterations <- 20000
source("Ca.Buffering.TLS.Sub.R")
setwd("F:/2013/kd estimation/CalciumBufferingTLS")
source("Ca.Buffering.TLS.Sub.R")
data.directory
data.directory = "F:/2013/kd estimation/CalciumBufferingTLS"
source("Ca.Buffering.TLS.Sub.R")
interactive.file.chooser
fluorescence.filename
data.directory = "F:/2013/kd estimation/CalciumBufferingTLS"
#The fluorescence measurement data:
fluorescence.filename = "f.csv"
#Fluorescence measurement error estimates:
fluorescence.se.filename = "f.sem.csv"
#Total calcium increment:
delta.ca.total.filename = "ca.csv"
#Total calcium increment error estimates:
delta.ca.total.se.filename = "ca.sem.csv"
source("Ca.Buffering.TLS.Sub.R")
data.directory
interactive.file.chooser = FALSE
#file path to the directory containing the data:
data.directory = "F:/2013/kd estimation/CalciumBufferingTLS"
#The fluorescence measurement data:
fluorescence.filename = "f.csv"
#Fluorescence measurement error estimates:
fluorescence.se.filename = "f.sem.csv"
#Total calcium increment:
delta.ca.total.filename = "d.ca.csv"
#Total calcium increment error estimates:
delta.ca.total.se.filename = "d.ca.sem.csv"
max.iterations <- 20000
F.MIN <- .01
F.MAX <- .995
# max.iterations specifies the maximum number of stochastic gradient descent iterations to perform. In the current verstion, reaching max.iterations is the only method for terminating the fit, and exactly max.iterations will always be performed.
max.iterations <- 20000
parameter.is.fixed <- c(rf = TRUE, kd.dye = FALSE, bt.dye = TRUE, kd.1 = FALSE, bt.1 = FALSE, kd.2 = TRUE, bt.2 = TRUE, kappa.nonsaturable = TRUE, accessible.volume = FALSE)
# The user must specify starting values for the parameters. The stochastic gradient descent algorithm is designed to escape local "false" optima in the parameter space that can be attributed to measurement noise. Therefore, it is not especially sensitive to starting estimates provided that a unique optimum exists. Extremely poor choices for starting parameters, however, may cause the algorithm to behave poorly. For parameters that are fixed, their values are fixed at the initial estimate provided in beta.
beta <- c(rf = 50, kd.dye = .400, bt.dye = 100, kd.1 = 2, bt.1 = 100, kd.2 = 0, bt.2 = 0, kappa.nonsaturable = 0, accessible.volume = .5  )
#The algorithm requires lower and upper bounds on parameters. Poor performance can be guaranteed by improper specification of the upper and lower bounds on beta. Some simple physical considerations provide guidelines for choosing good boundaries. Clearly the kd for the dye and any endogenous buffers must be positive. If the kd of the endogenous buffer were too large then it would not even partially saturate over the range of observable free calcium values. Therefore, the upper bounds on the endogenous buffer kd's may be taken to be some multiple of the dye kd. Extremely low affinity buffers can be modeled as nonsaturable buffers. The nonsaturable buffering capacity, if present, must be strictly nonnegative and an upper limit must be estimated by considerations of the preparation. Strictly speaking, the fraction of accessible volume must be less than or equal to one, however, some allowance should be made for under estimation of the total volume.  The lower boundary for the fraction of accessible volume must be strictly greater than zero, and a suitable value may be estimated from knowledge of the preparation.
beta.lower <- c(rf = 20, kd.dye = .1, bt.dye = 50, kd.1 = 0, bt.1 = 0, kd.2 = 0, bt.2 = 0, kappa.nonsaturable = 0, accessible.volume = .05)
beta.upper <- c(rf = 200, kd.dye = 2, bt.dye = 200, kd.1 = 10, bt.1 = 1000, kd.2 = 10, bt.2 = 1000, kappa.nonsaturable = 200, accessible.volume = 1.1)
# parameter.names specifies the names of the parameters, this is used only to write output files
parameter.names <- c("rf", "kd.dye", "bt.dye", "kd.endogenous.1", "bt.endogenous.1", "kd.endogenous.2", "bt.endogenous.2", "kappa.nonsaturable", "accessible.volume")
do.bootstrap.estimate = FALSE
bootstrap.replicates = 8
n.threads = 4
replace.on.boundary = TRUE
boundary.margin = (beta.upper - beta.lower) * (.Machine$double.eps)^.5
#The data files may be specefied in one of two ways. If interactive.file.chooser = TRUE then, when this script is ran, the user will select the files interactively through a file chooser dialog box. If interactive.file.chooser = FALSE then the file names with full paths must be specefied below.
interactive.file.chooser = FALSE
#file path to the directory containing the data:
data.directory = "F:/2013/kd estimation/CalciumBufferingTLS"
#The fluorescence measurement data:
fluorescence.filename = "f.csv"
#Fluorescence measurement error estimates:
fluorescence.se.filename = "f.sem.csv"
#Total calcium increment:
delta.ca.total.filename = "d.ca.csv"
#Total calcium increment error estimates:
delta.ca.total.se.filename = "d.ca.sem.csv"
source("Ca.Buffering.TLS.Sub.R")
data.directory = "F:/2013/kd estimation/CalciumBufferingTLS"
#The fluorescence measurement data:
fluorescence.filename = "f.csv"
#Fluorescence measurement error estimates:
fluorescence.se.filename = "f.sem.csv"
#Total calcium increment:
delta.ca.total.filename = "d.ca.csv"
#Total calcium increment error estimates:
delta.ca.total.se.filename = "d.ca.sem.csv"
source('F:/2013/kd estimation/CalciumBufferingTLS/Run.Ca.Buffering.TLS.R')
p.goto.best.par = .005
#file path to the directory containing the data:
data.directory = "F:/2013/kd estimation/CalciumBufferingTLS"
#The fluorescence measurement data:
fluorescence.filename = "f.csv"
#Fluorescence measurement error estimates:
fluorescence.se.filename = "f.sem.csv"
#Total calcium increment:
delta.ca.total.filename = "d.ca.csv"
#Total calcium increment error estimates:
delta.ca.total.se.filename = "d.ca.sem.csv"
parameter.boundary.margin = .01
# p.restart: if the parameters are "too close to the boundary" as defined above, then the reset behavior described above is executed with probability p.restart
p.restart = 1
#p.restart.decay: if the parameters are reset, then p.restart = p.restart * p.restart.decay, this option is included to prevent the algorithm from restarting at every iteration, which may happen if the parameter limits are poorly chosen or on certain data sets
p.restart.decay = .5
# p.restart.grow: if the parameters are on the boundary and a restart action is not performed, then p.restart = p.restart * p.restart.grow
p.restart.grow = 1.1
# p.check.obj: evaluating the toal least squares objective function is very computationaly intensive, therefore we perform the evaluation with probability p.check.obj
p.check.obj = .05
# p.goto.best.par: with probably p.goto.best.par set beta to the best parameters observed so far
p.goto.best.par = .005
source("Ca.Buffering.TLS.Sub.R")
.999^25000
.9995^25000
.9999^25000
.9996^25000
.9995^25000
sgd.result
sgd.result$par
beta <- sgd.result$par
source('F:/2013/kd estimation/CalciumBufferingTLS/Run.Ca.Buffering.TLS.R')
source("Ca.Buffering.TLS.Sub.R")
parameter.boundary.margin
p.restart
p.restart.decay
p.restart.grow
interactive.file.chooser = FALSE
#file path to the directory containing the data:
data.directory = "F:/2013/kd estimation/CalciumBufferingTLS"
#The fluorescence measurement data:
fluorescence.filename = "f.csv"
#Fluorescence measurement error estimates:
fluorescence.se.filename = "f.sem.csv"
#Total calcium increment:
delta.ca.total.filename = "d.ca.csv"
#Total calcium increment error estimates:
delta.ca.total.se.filename = "d.ca.sem.csv"
source("Ca.Buffering.TLS.Sub.R")
source('~/.active-rstudio-document')
sgd.result <- S.G.D.C(beta = beta, x = x, y = y, x.weight = x.weight, y.weight = y.weight, x.min = x.min, x.max = x.max, beta.lower = beta.lower, beta.upper = beta.upper, ifixb = ifixb, max.iter = max.iterations, data.env = tls.data.env, Fxn = Delta.Ca.Total.Hat.C, parameter.boundary.margin = parameter.boundary.margin, p.restart = p.restart, p.restart.decay = p.restart.decay,   p.restart.grow = p.restart.grow, p.check.obj = p.check.obj, p.goto.best.par = p.goto.best.par)
max.iter = max.iterations
data.env = tls.data.env
Fxn = Delta.Ca.Total.Hat.C
p.restart
p.restart.decay
p.restart.grow
p.check.obj
p.goto.best.par
if(is.null(x.error)){
x.error <- x*0
}
x.error=NULL
x.min
beta.lower
Objective.Fxn
Objective.Fxn = T.L.S.C
solution.tolerance
solution.tolerance=.Machine$double.eps^.5
max.iter
num.steps
Grad
Grad = T.L.S.Gradient.C
decay.constant
data.env
Fxn
parameter.boundary.margin
p.restart
p.restart.decay
p.restart.grow
p.check.obj
p.goto.best.par
if(is.null(x.error)){
x.error <- x*0
}
ifixb <- as.logical(ifixb)
n.row <- nrow(x)
n.col.x <- ncol(x)
n.col.y <- ncol(y)
Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
nls.fit <- nls.lm(par = beta[!ifixb],lower = beta.lower[!ifixb] ,upper = beta.upper[!ifixb] ,fn = Objective.Fxn, ifixb = ifixb, ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, beta.lower = beta.lower, beta.upper = beta.upper, return.vector = TRUE, Fxn = Fxn, x.error = x.error, beta2 = beta, tls.env = data.env, x.max = x.max, x.min = x.min )
beta[!ifixb] <- nls.fit$par
best.par <- beta
best.int.par <- beta
best.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
print(best.val)
print(best.par)
j <- 1
k<-1
eta <- (beta.upper - beta.lower)/num.steps
eta
if(any(!is.finite(eta))){
eta <- rep(x = 1/num.steps, times = sum(!ifixb))
}
eta
reshuffle.counter <- 0
shuffle.seq <- resample(seq(n.row))
reshuffle.counter <- reshuffle.counter + 1
eta <- eta * decay.constant
eta
if(runif(1) < p.check.obj){
new.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
if(new.val < best.val){
x.error <- data.env$x.error
nls.fit <- nls.lm(par = beta[!ifixb],lower = beta.lower[!ifixb] ,upper = beta.upper[!ifixb] ,fn = Objective.Fxn, ifixb = ifixb, ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, beta.lower = beta.lower, beta.upper = beta.upper, return.vector = TRUE, Fxn = Fxn, x.error = x.error, beta2 = beta, tls.env = data.env, x.max = x.max, x.min = x.min )
beta[!ifixb] <- nls.fit$par
best.par <- beta
parameter.on.boundary <- any(beta[!ifixb] < beta.lower[!ifixb] + (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin) | any(beta[!ifixb] > beta.upper[!ifixb] - (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin)
if(!parameter.on.boundary){
best.int.par <- beta
}
best.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
print(best.val)
print(beta)
}
}else{
if(runif(1) < p.goto.best.par){
beta <- best.int.par
new.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
}
}
if(reshuffle.counter > nrow(x)-1){
shuffle.seq <- resample(seq(nrow(x)))
reshuffle.counter <- 1
parameter.on.boundary <- any(beta[!ifixb] < beta.lower[!ifixb] + (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin) | any(beta[!ifixb] > beta.upper[!ifixb] - (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin)
if(parameter.on.boundary){
#if parameters on boundary, then randomly reset parameters or do nothing. The method for resetting parameters is randomly chosen between:
#1: randomly reset parameters
#2: set beta to previous best point on interior of parameter space
if(runif(1) < p.restart){
p.restart <- p.restart * p.restart.decay
if(resample(c(TRUE,FALSE), 1)){
beta[!ifixb] <-  beta.lower[!ifixb] + (beta.upper[!ifixb] - beta.lower[!ifixb]) * runif(sum(!ifixb), min = parameter.boundary.margin, max = (1-parameter.boundary.margin))
}else{
beta <- best.int.par
}
x.error <- matrix(0, nrow = n.row, ncol = n.col.x)
Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
nls.fit <- nls.lm(par = beta[!ifixb],lower = beta.lower[!ifixb] ,upper = beta.upper[!ifixb] ,fn = Objective.Fxn, ifixb = ifixb, ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, beta.lower = beta.lower, beta.upper = beta.upper, return.vector = TRUE, Fxn = Fxn, x.error = x.error, beta2 = beta, tls.env = data.env, x.max = x.max, x.min = x.min )
beta[!ifixb] <- nls.fit$par
#         eta <- (beta.upper - beta.lower)/num.steps
}else{
p.restart <- p.restart * p.restart.grow
}
}
current.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
print(j)
if(current.val < best.val){
nls.fit <- nls.lm(par = beta[!ifixb],lower = beta.lower[!ifixb] ,upper = beta.upper[!ifixb] ,fn = Objective.Fxn, ifixb = ifixb, ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, beta.lower = beta.lower, beta.upper = beta.upper, return.vector = TRUE, Fxn = Fxn, x.error = x.error, beta2 = beta, tls.env = data.env, x.max = x.max, x.min = x.min )
beta[!ifixb] <- nls.fit$par
best.par <- beta
parameter.on.boundary <- any(beta[!ifixb] < beta.lower[!ifixb] + (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin) | any(beta[!ifixb] > beta.upper[!ifixb] - (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin)
if(!parameter.on.boundary){
best.int.par <- beta
}
best.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
print(best.val)
print(best.par)
parameter.on.boundary <- any(beta[!ifixb] < beta.lower[!ifixb] + (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin) | any(beta[!ifixb] > beta.upper[!ifixb] - (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin)
if(!parameter.on.boundary){
best.in.par <- beta
}
}
}
delta <- Grad(beta = beta,x = matrix(x[shuffle.seq[reshuffle.counter],] ,ncol = ncol(x)), y = matrix(y[shuffle.seq[reshuffle.counter],], ncol = ncol(y)), x.error = matrix(x.error[shuffle.seq[reshuffle.counter],], ncol = ncol(x)), x.weight = matrix(x.weight[shuffle.seq[reshuffle.counter],], ncol = ncol(x)), y.weight = matrix(y.weight[shuffle.seq[reshuffle.counter],], ncol = ncol(y)), beta.lower = beta.lower, beta.upper = beta.upper, Fxn = Fxn, ifixx = FALSE, ifixb = ifixb,tls.env = new.env(), x.min = x.min, x.max = x.max )
while(any(((beta - eta*delta) < beta.lower) | ((beta - eta*delta) > beta.upper))){
delta <- delta/10
}
beta <- beta - eta * delta
beta[beta < beta.lower] <- beta.lower[beta < beta.lower]
beta[beta > beta.upper] <- beta.upper[beta > beta.upper]
j <- j + 1
while(j <= max.iter){
reshuffle.counter <- reshuffle.counter + 1
eta <- eta * decay.constant
if(runif(1) < p.check.obj){
new.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
if(new.val < best.val){
x.error <- data.env$x.error
nls.fit <- nls.lm(par = beta[!ifixb],lower = beta.lower[!ifixb] ,upper = beta.upper[!ifixb] ,fn = Objective.Fxn, ifixb = ifixb, ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, beta.lower = beta.lower, beta.upper = beta.upper, return.vector = TRUE, Fxn = Fxn, x.error = x.error, beta2 = beta, tls.env = data.env, x.max = x.max, x.min = x.min )
beta[!ifixb] <- nls.fit$par
best.par <- beta
parameter.on.boundary <- any(beta[!ifixb] < beta.lower[!ifixb] + (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin) | any(beta[!ifixb] > beta.upper[!ifixb] - (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin)
if(!parameter.on.boundary){
best.int.par <- beta
}
best.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
print(best.val)
print(beta)
}
}else{
if(runif(1) < p.goto.best.par){
beta <- best.int.par
new.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
}
}
if(reshuffle.counter > nrow(x)-1){
shuffle.seq <- resample(seq(nrow(x)))
reshuffle.counter <- 1
parameter.on.boundary <- any(beta[!ifixb] < beta.lower[!ifixb] + (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin) | any(beta[!ifixb] > beta.upper[!ifixb] - (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin)
if(parameter.on.boundary){
#if parameters on boundary, then randomly reset parameters or do nothing. The method for resetting parameters is randomly chosen between:
#1: randomly reset parameters
#2: set beta to previous best point on interior of parameter space
if(runif(1) < p.restart){
p.restart <- p.restart * p.restart.decay
if(resample(c(TRUE,FALSE), 1)){
beta[!ifixb] <-  beta.lower[!ifixb] + (beta.upper[!ifixb] - beta.lower[!ifixb]) * runif(sum(!ifixb), min = parameter.boundary.margin, max = (1-parameter.boundary.margin))
}else{
beta <- best.int.par
}
x.error <- matrix(0, nrow = n.row, ncol = n.col.x)
Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
nls.fit <- nls.lm(par = beta[!ifixb],lower = beta.lower[!ifixb] ,upper = beta.upper[!ifixb] ,fn = Objective.Fxn, ifixb = ifixb, ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, beta.lower = beta.lower, beta.upper = beta.upper, return.vector = TRUE, Fxn = Fxn, x.error = x.error, beta2 = beta, tls.env = data.env, x.max = x.max, x.min = x.min )
beta[!ifixb] <- nls.fit$par
#         eta <- (beta.upper - beta.lower)/num.steps
}else{
p.restart <- p.restart * p.restart.grow
}
}
current.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
print(j)
if(current.val < best.val){
nls.fit <- nls.lm(par = beta[!ifixb],lower = beta.lower[!ifixb] ,upper = beta.upper[!ifixb] ,fn = Objective.Fxn, ifixb = ifixb, ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, beta.lower = beta.lower, beta.upper = beta.upper, return.vector = TRUE, Fxn = Fxn, x.error = x.error, beta2 = beta, tls.env = data.env, x.max = x.max, x.min = x.min )
beta[!ifixb] <- nls.fit$par
best.par <- beta
parameter.on.boundary <- any(beta[!ifixb] < beta.lower[!ifixb] + (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin) | any(beta[!ifixb] > beta.upper[!ifixb] - (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin)
if(!parameter.on.boundary){
best.int.par <- beta
}
best.val <- Objective.Fxn(beta = beta,ifixb = ifixb,ifixx = FALSE, y = y, x = x, x.weight = x.weight, y.weight = y.weight, Fxn = Fxn, x.error = x.error, tls.env = data.env, x.min = x.min, x.max = x.max  )
x.error <- data.env$x.error
print(best.val)
print(best.par)
parameter.on.boundary <- any(beta[!ifixb] < beta.lower[!ifixb] + (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin) | any(beta[!ifixb] > beta.upper[!ifixb] - (beta.upper[!ifixb] - beta.lower[!ifixb]) * parameter.boundary.margin)
if(!parameter.on.boundary){
best.in.par <- beta
}
}
}
delta <- Grad(beta = beta,x = matrix(x[shuffle.seq[reshuffle.counter],] ,ncol = ncol(x)), y = matrix(y[shuffle.seq[reshuffle.counter],], ncol = ncol(y)), x.error = matrix(x.error[shuffle.seq[reshuffle.counter],], ncol = ncol(x)), x.weight = matrix(x.weight[shuffle.seq[reshuffle.counter],], ncol = ncol(x)), y.weight = matrix(y.weight[shuffle.seq[reshuffle.counter],], ncol = ncol(y)), beta.lower = beta.lower, beta.upper = beta.upper, Fxn = Fxn, ifixx = FALSE, ifixb = ifixb,tls.env = new.env(), x.min = x.min, x.max = x.max )
while(any(((beta - eta*delta) < beta.lower) | ((beta - eta*delta) > beta.upper))){
delta <- delta/10
}
beta <- beta - eta * delta
beta[beta < beta.lower] <- beta.lower[beta < beta.lower]
beta[beta > beta.upper] <- beta.upper[beta > beta.upper]
#     print(j)
j <- j + 1
}
source('F:/2013/kd estimation/CalciumBufferingTLS/Run.Ca.Buffering.TLS.R')
